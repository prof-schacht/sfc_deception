{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab # type: ignore\n",
    "    from google.colab import output\n",
    "    COLAB = True\n",
    "    %pip install sae-lens transformer-lens\n",
    "except:\n",
    "    COLAB = False\n",
    "    from IPython import get_ipython # type: ignore\n",
    "    ipython = get_ipython(); assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import einops\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Device setup\n",
    "GPU_TO_USE = 2\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = f\"cuda:{GPU_TO_USE}\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# utility to clear variables out of the memory & and clearing cuda cache\n",
    "import gc\n",
    "def clear_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_data_path(data_folder, in_colab=COLAB):\n",
    "  if in_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    return Path(f'/content/drive/MyDrive/{data_folder}')\n",
    "  else:\n",
    "    return Path(f'./{data_folder}')\n",
    "  \n",
    "datapath = get_data_path('./data')\n",
    "datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (sfc_deception) to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gemma-2-9b-it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bfc22c1d2146d6b02f1f0137eacd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-9b-it into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedSAETransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-41): 42 x TransformerBlock(\n",
       "      (ln1): RMSNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln1_post): RMSNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): RMSNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2_post): RMSNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "        (hook_rot_k): HookPoint()\n",
       "        (hook_rot_q): HookPoint()\n",
       "      )\n",
       "      (mlp): GatedMLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_pre_linear): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): RMSNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_lens import SAE, HookedSAETransformer, ActivationsStore\n",
    "\n",
    "USE_INSTRUCT = True\n",
    "PARAMS_COUNT = 9\n",
    "\n",
    "MODEL_NAME = f'gemma-2-{PARAMS_COUNT}b' + ('-it' if USE_INSTRUCT else '')\n",
    "print(f'Using {MODEL_NAME}')\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(MODEL_NAME, device=device, dtype=torch.bfloat16)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.sfc_data_loader import SFCDatasetLoader\n",
    "import utils.prompts as prompts\n",
    "from utils.enums import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = SupportedDatasets.COMMONSENSE_QA_FILTERED\n",
    "CHOOSE_N_SAMPLES = 1000\n",
    "\n",
    "if DATASET_NAME in [SupportedDatasets.CITIES, SupportedDatasets.FACTS, SupportedDatasets.COMPANIES]:\n",
    "    dataloader = SFCDatasetLoader(DATASET_NAME, model, \n",
    "                                  clean_system_prompt=prompts.TRUTH_OR_USER_KILLED,\n",
    "                                  corrupted_system_prompt=prompts.LIE_OR_USER_KILLED,\n",
    "                                  task_prompt=prompts.ANSWER_TRUE_FALSE,\n",
    "                                  local_dataset=True, base_folder_path=datapath,\n",
    "                                  )\n",
    "elif DATASET_NAME in [SupportedDatasets.COMMONSENSE_QA, SupportedDatasets.COMMONSENSE_QA_FILTERED]:\n",
    "    dataloader = SFCDatasetLoader(DATASET_NAME, model, \n",
    "                                clean_system_prompt=prompts.TRUTH_OR_USER_KILLED,\n",
    "                                corrupted_system_prompt=prompts.LIE_OR_USER_KILLED,\n",
    "                                task_prompt=prompts.OUTPUT_SINGLE_LETTER,\n",
    "                                num_samples=CHOOSE_N_SAMPLES)\n",
    "elif DATASET_NAME in [SupportedDatasets.VERB_AGREEMENT]:\n",
    "    dataloader = SFCDatasetLoader(DATASET_NAME, model,\n",
    "                                  local_dataset=True, base_folder_path=datapath)\n",
    "else:\n",
    "    raise ValueError(f\"Dataset {DATASET_NAME.value} is not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figuring out optimal padding length...\n",
      "Filtered out 10 longest prompts from a total of 1000 prompts.\n",
      "Setting max prompt length to 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:02<00:00, 403.12it/s]\n"
     ]
    }
   ],
   "source": [
    "if DATASET_NAME in [SupportedDatasets.VERB_AGREEMENT]:\n",
    "    clean_dataset, corrupted_dataset = dataloader.get_clean_corrupted_datasets(tokenize=True, apply_chat_template=False, prepend_generation_prefix=True)\n",
    "else:\n",
    "    clean_dataset, corrupted_dataset = dataloader.get_clean_corrupted_datasets(tokenize=True, apply_chat_template=True, prepend_generation_prefix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 175)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTROL_SEQ_LEN = clean_dataset['control_sequence_length'][0].item()\n",
    "N_CONTEXT = clean_dataset['prompt'].shape[1]\n",
    "\n",
    "CONTROL_SEQ_LEN, N_CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(start_idx=0, end_idx=-1, clean_dataset=None, corrupted_dataset=None):\n",
    "    assert clean_dataset is not None or corrupted_dataset is not None, 'At least one dataset must be provided.'\n",
    "    return_values = []\n",
    "\n",
    "    for key in ['prompt', 'answer', 'answer_pos', 'attention_mask', 'special_token_mask']:\n",
    "        if clean_dataset is not None:\n",
    "            return_values.append(clean_dataset[key][start_idx:end_idx])\n",
    "        if corrupted_dataset is not None:\n",
    "            return_values.append(corrupted_dataset[key][start_idx:end_idx])\n",
    "\n",
    "    return return_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_logit(logits: Float[Tensor, \"batch pos d_vocab\"], \n",
    "                     clean_answers: Int[Tensor, \"batch\"],\n",
    "                     ansnwer_pos: Int[Tensor, \"batch\"], return_all_logits=False) -> Float[Tensor, \"batch\"]:\n",
    "\n",
    "    answer_pos_idx = einops.repeat(ansnwer_pos, 'batch -> batch 1 d_vocab',\n",
    "                                   d_vocab=logits.shape[-1])\n",
    "    answer_logits = logits.gather(1, answer_pos_idx).squeeze(1) # shape [batch, d_vocab]\n",
    "\n",
    "    correct_logits = answer_logits.gather(1, clean_answers.unsqueeze(1)).squeeze(1) # shape [batch]\n",
    "\n",
    "    if return_all_logits:\n",
    "        return answer_logits, correct_logits\n",
    "\n",
    "    return correct_logits\n",
    "\n",
    "def get_incorrect_logits(logits: Float[Tensor, \"batch pos d_vocab\"],\n",
    "                         patched_answers: Int[Tensor, \"batch count\"],\n",
    "                         answer_pos: Int[Tensor, \"batch\"], patch_answer_reduce='max') -> Float[Tensor, \"batch\"]:\n",
    "    \n",
    "    answer_pos_idx = einops.repeat(answer_pos, 'batch -> batch 1 d_vocab',\n",
    "                                   d_vocab=logits.shape[-1])\n",
    "    answer_logits = logits.gather(1, answer_pos_idx).squeeze(1) # shape [batch, d_vocab]\n",
    "\n",
    "    incorrect_logits = answer_logits.gather(1, patched_answers)  # shape [batch, answer_count]\n",
    "\n",
    "    # Sum the logits for each incorrect answer option\n",
    "    if patch_answer_reduce == 'sum':\n",
    "        incorrect_logits = incorrect_logits.sum(dim=1)\n",
    "    # Or take their maximum: this should be a better option to avoid situations where the model outputs gibberish and all the answers have similar logits\n",
    "    elif patch_answer_reduce == 'max':\n",
    "        incorrect_logits = incorrect_logits.max(dim=1).values\n",
    "\n",
    "    return incorrect_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablate_hook(act, hook):\n",
    "    act[:] = 0\n",
    "    return act\n",
    "\n",
    "# Define a function to run ablation analysis\n",
    "def run_ablation_batch_analysis(\n",
    "    batch_size=64,\n",
    "    hook_types: list[str] = [\"hook_mlp_out\", \"attn.hook_z\"],\n",
    "    n_layers = model.cfg.n_layers,\n",
    "    model=model,\n",
    "    clean_dataset=clean_dataset,\n",
    "    corrupted_dataset=corrupted_dataset,\n",
    "    clean_prompt_run=True,\n",
    "):\n",
    "    num_samples = len(clean_dataset['prompt']) # [batch_size, seq_len]\n",
    "    total_batches = num_samples // batch_size\n",
    "\n",
    "    if num_samples % batch_size != 0:\n",
    "        total_batches += 1\n",
    "\n",
    "    # For each hook type, the differences tensor will contain 2 elements for each layer:\n",
    "    # difference in the correct logit and difference in the max incorrect logit\n",
    "    differences_dict = {hook: torch.zeros(n_layers, 2, device=model.cfg.device) for hook in hook_types}\n",
    "    \n",
    "    for i in tqdm(range(0, num_samples, batch_size)):\n",
    "        clean_prompts, corrupted_prompts, clean_answers, corrupted_answers, clean_answers_pos, corrupted_answers_pos, \\\n",
    "        clean_attn_mask, corrupted_attn_mask, clean_special_mask, corr_special_mask = sample_dataset(i, i + batch_size, clean_dataset, corrupted_dataset)\n",
    "        if clean_prompt_run:\n",
    "            prompts = clean_prompts\n",
    "            answers_pos = clean_answers_pos\n",
    "            attn_mask = clean_attn_mask\n",
    "        else:\n",
    "            prompts = corrupted_prompts\n",
    "            answers_pos = corrupted_answers_pos\n",
    "            attn_mask = corrupted_attn_mask\n",
    "\n",
    "        # Get baseline logits\n",
    "        baseline_logits = model(prompts, attention_mask=attn_mask)  # [batch_size, seq_len, n_tokens]\n",
    "\n",
    "        baseline_correct_logits = get_answer_logit(baseline_logits, clean_answers, answers_pos)\n",
    "        baseline_incorrect_logits = get_incorrect_logits(baseline_logits, corrupted_answers, answers_pos)\n",
    "\n",
    "        print(f'Mean incorrect - correct difference: {baseline_incorrect_logits.mean() - baseline_correct_logits.mean()}')\n",
    "\n",
    "        clear_cache()\n",
    "        # Run ablations for each layer and hook type\n",
    "        for layer in tqdm(range(n_layers)):\n",
    "            for hook_type in hook_types:\n",
    "                hook_name = f\"blocks.{layer}.{hook_type}\"\n",
    "\n",
    "                ablated_logits = model.run_with_hooks(prompts, attention_mask=attn_mask, \n",
    "                                                     fwd_hooks=[(hook_name, ablate_hook)]  # [batch_size, seq_len, n_tokens]\n",
    "                                                     )   # [batch_size, seq_len, n_tokens]\n",
    "                \n",
    "                ablated_correct_logits = get_answer_logit(ablated_logits, clean_answers, answers_pos)\n",
    "                ablated_incorrect_logits = get_incorrect_logits(ablated_logits, corrupted_answers, answers_pos)\n",
    "                \n",
    "                # Calculate differences from baseline\n",
    "                correct_logit_dif = baseline_correct_logits - ablated_correct_logits  # [batch_size, seq_len, n_tokens]\n",
    "                incorrect_logit_dif = baseline_incorrect_logits - ablated_incorrect_logits  # [batch_size, seq_len, n_tokens]\n",
    "\n",
    "                # Store the mean difference over the batch\n",
    "                differences_dict[hook_type][layer, 0] += correct_logit_dif.mean()\n",
    "                differences_dict[hook_type][layer, 1] += incorrect_logit_dif.mean()\n",
    "            clear_cache()\n",
    "\n",
    "    # Finally, compute the mean over the outer batches\n",
    "    for hook_type in hook_types:\n",
    "        differences_dict[hook_type] /= total_batches\n",
    "\n",
    "    return differences_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = model.cfg.n_layers\n",
    "BATCH_SIZE = 87\n",
    "HOOK_TYPES = [\"hook_mlp_out\", \"attn.hook_z\"]\n",
    "\n",
    "clear_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -5.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:58<00:00,  2.81s/it]\n",
      "  8%|▊         | 1/12 [01:59<21:55, 119.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:59<00:00,  2.85s/it]\n",
      " 17%|█▋        | 2/12 [04:00<20:06, 120.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -4.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:59<00:00,  2.85s/it]\n",
      " 25%|██▌       | 3/12 [06:02<18:09, 121.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -5.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:59<00:00,  2.85s/it]\n",
      " 33%|███▎      | 4/12 [08:04<16:09, 121.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -5.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:59<00:00,  2.85s/it]\n",
      " 42%|████▏     | 5/12 [10:05<14:09, 121.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -4.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:59<00:00,  2.85s/it]\n",
      " 50%|█████     | 6/12 [12:06<12:08, 121.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -4.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:00<00:00,  2.86s/it]\n",
      " 58%|█████▊    | 7/12 [14:08<10:07, 121.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [01:59<00:00,  2.85s/it]\n",
      " 67%|██████▋   | 8/12 [16:10<08:05, 121.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -5.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:00<00:00,  2.86s/it]\n",
      " 75%|███████▌  | 9/12 [18:11<06:04, 121.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -5.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:00<00:00,  2.87s/it]\n",
      " 83%|████████▎ | 10/12 [20:13<04:03, 121.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -4.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:00<00:00,  2.86s/it]\n",
      " 92%|█████████▏| 11/12 [22:15<02:01, 121.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: -4.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:51<00:00,  1.23s/it]\n",
      "100%|██████████| 12/12 [23:08<00:00, 115.70s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_difs_dict = run_ablation_batch_analysis(batch_size=BATCH_SIZE, n_layers=N_LAYERS)\n",
    "ablation_difs_dict['hook_mlp_out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer': 0,\n",
       " 'hook_type': 'hook_mlp_out',\n",
       " 'logit_diffs': array([ 0.33113608, -0.61083984], dtype=float32)}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for hook_type in HOOK_TYPES:\n",
    "    for layer in range(N_LAYERS):\n",
    "        result = {\n",
    "            'layer': layer,\n",
    "            'hook_type': hook_type,\n",
    "            'logit_diffs': ablation_difs_dict[hook_type][layer].cpu().numpy(),\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_logit_diffs(data, title_suffix=\"\"):\n",
    "    # Group by hook_type\n",
    "    grouped_data = {}\n",
    "    for entry in data:\n",
    "        hook_type = entry['hook_type']\n",
    "        if hook_type not in grouped_data:\n",
    "            grouped_data[hook_type] = []\n",
    "        grouped_data[hook_type].append(entry)\n",
    "\n",
    "    # Define color scheme for consistency\n",
    "    correct_color = 'blue'\n",
    "    incorrect_color = 'red'\n",
    "\n",
    "    # Create subplots without shared x-axes\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=False,  # Disable shared x-axes\n",
    "        subplot_titles=(\n",
    "            \"hook_mlp_out Logit Differences\",\n",
    "            \"attn.hook_z Logit Differences\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Plot for hook_type = 'hook_mlp_out'\n",
    "    if 'hook_mlp_out' in grouped_data:\n",
    "        layers = [entry['layer'] for entry in grouped_data['hook_mlp_out']]\n",
    "        logit_diffs_correct = [entry['logit_diffs'][0] for entry in grouped_data['hook_mlp_out']]\n",
    "        logit_diffs_incorrect = [entry['logit_diffs'][1] for entry in grouped_data['hook_mlp_out']]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name=\"Correct Answer Logit-Dif\",\n",
    "                x=layers,\n",
    "                y=logit_diffs_correct,\n",
    "                marker_color=correct_color  # Apply consistent color\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name=\"Max(Incorrect) Answer Logit-Dif\",\n",
    "                x=layers,\n",
    "                y=logit_diffs_incorrect,\n",
    "                marker_color=incorrect_color  # Apply consistent color\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    # Plot for hook_type = 'attn.hook_z'\n",
    "    if 'attn.hook_z' in grouped_data:\n",
    "        layers = [entry['layer'] for entry in grouped_data['attn.hook_z']]\n",
    "        logit_diffs_correct = [entry['logit_diffs'][0] for entry in grouped_data['attn.hook_z']]\n",
    "        logit_diffs_incorrect = [entry['logit_diffs'][1] for entry in grouped_data['attn.hook_z']]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name=\"Correct Answer Logit-Dif\",\n",
    "                x=layers,\n",
    "                y=logit_diffs_correct,\n",
    "                marker_color=correct_color,  # Consistent color\n",
    "                showlegend=False  # Hide duplicate legend entry\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name=\"Max(Incorrect) Answer Logit-Dif\",\n",
    "                x=layers,\n",
    "                y=logit_diffs_incorrect,\n",
    "                marker_color=incorrect_color,  # Consistent color\n",
    "                showlegend=False  # Hide duplicate legend entry\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,  # Adjusted height for visibility\n",
    "        width=1200,\n",
    "        title_text=f\"Ablation logit differences: {title_suffix}\",\n",
    "        barmode='group'  # Group bars side by side for comparison\n",
    "    )\n",
    "\n",
    "    # Update x-axes to show all layer ticks and add x-axis labels\n",
    "    # For the first subplot\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"Layer\",\n",
    "        tickmode='linear',\n",
    "        dtick=1,  # Show every tick\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # For the second subplot\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"Layer\",\n",
    "        tickmode='linear',\n",
    "        dtick=1,  # Show every tick\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Update y-axes titles\n",
    "    fig.update_yaxes(title_text=\"Logit Difference<br>(Baseline - Ablated)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Logit Difference<br>(Baseline - Ablated)\", row=2, col=1)\n",
    "\n",
    "    # Optionally, adjust the range of x-axes if layers are from 1 to 42\n",
    "    fig.update_xaxes(range=[1, N_LAYERS], row=1, col=1)\n",
    "    fig.update_xaxes(range=[1, N_LAYERS], row=2, col=1)\n",
    "\n",
    "    # Display the figure\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "plot_logit_diffs(results, title_suffix='Clean setting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrupted prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:00<00:00,  2.87s/it]\n",
      "  8%|▊         | 1/12 [02:02<22:23, 122.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 17%|█▋        | 2/12 [04:05<20:27, 122.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 25%|██▌       | 3/12 [06:08<18:25, 122.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 1.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 33%|███▎      | 4/12 [08:11<16:22, 122.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 2.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 42%|████▏     | 5/12 [10:14<14:20, 122.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 2.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.90s/it]\n",
      " 50%|█████     | 6/12 [12:17<12:18, 123.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 1.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 58%|█████▊    | 7/12 [14:20<10:15, 123.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 67%|██████▋   | 8/12 [16:23<08:12, 123.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 75%|███████▌  | 9/12 [18:26<06:09, 123.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 83%|████████▎ | 10/12 [20:29<04:06, 123.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [02:01<00:00,  2.89s/it]\n",
      " 92%|█████████▏| 11/12 [22:32<02:03, 123.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean incorrect - correct difference: 2.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:49<00:00,  1.19s/it]\n",
      "100%|██████████| 12/12 [23:23<00:00, 116.94s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablation_difs_dict = run_ablation_batch_analysis(batch_size=BATCH_SIZE, n_layers=N_LAYERS, clean_prompt_run=False)\n",
    "ablation_difs_dict['hook_mlp_out'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "blue"
         },
         "name": "Correct Answer Logit-Dif",
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "xaxis": "x",
         "y": [
          0.3909098505973816,
          -0.3194987177848816,
          0.1763204038143158,
          0.8463541865348816,
          1.9016927480697632,
          1.5807292461395264,
          1.7727864980697632,
          1.1223958730697632,
          0.4496307373046875,
          3.7890625,
          -1.0960286855697632,
          -1.1604818105697632,
          -0.3006591796875,
          0.4226888120174408,
          -2.2565104961395264,
          -0.7977702021598816,
          -2.2623698711395264,
          -0.588623046875,
          -2.1165366172790527,
          -1.302734375,
          0.6897786855697632,
          -0.3949788510799408,
          -1.2916667461395264,
          -0.42626953125,
          -2.0748698711395264,
          -1.4036458730697632,
          -0.8994140625,
          -0.59033203125,
          -0.25048828125,
          -0.6793619990348816,
          -0.4850260615348816,
          -0.3937174677848816,
          -0.3411458432674408,
          -0.6783854365348816,
          -0.30712890625,
          -0.2246907651424408,
          -0.3177083432674408,
          1.4466146230697632,
          0.49072265625,
          -0.1345621794462204,
          0.1212361678481102,
          -2.42578125
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "red"
         },
         "name": "Max(Incorrect) Answer Logit-Dif",
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "xaxis": "x",
         "y": [
          -0.3805338740348816,
          -0.04638671875,
          -0.1916300505399704,
          -0.2562662959098816,
          -0.5060221552848816,
          -0.5107421875,
          -0.49072265625,
          -0.28143310546875,
          -0.19476318359375,
          -0.5506185293197632,
          0.357666015625,
          0.5701497793197632,
          0.2328592985868454,
          -0.16940180957317352,
          2.4342448711395264,
          0.8600260615348816,
          2.9166667461395264,
          0.6474609375,
          2.76171875,
          0.779296875,
          -0.3954264521598816,
          0.60986328125,
          0.37818145751953125,
          -0.6396484375,
          0.5628255605697632,
          -0.5665690302848816,
          -0.701171875,
          -0.0988667830824852,
          -0.1597493588924408,
          -0.2867838740348816,
          -0.3430989682674408,
          -0.1761067807674408,
          -0.2496744841337204,
          -0.294189453125,
          -0.4217122495174408,
          -0.03450775146484375,
          0.0131963100284338,
          0.546875,
          0.7047526240348816,
          -0.0281016044318676,
          -0.0376637801527977,
          -2.4622397422790527
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "blue"
         },
         "name": "Correct Answer Logit-Dif",
         "showlegend": false,
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "xaxis": "x2",
         "y": [
          1.1962890625,
          -0.3151041865348816,
          0.3368327021598816,
          1.921875,
          1.4029948711395264,
          0.12837982177734375,
          2.3111979961395264,
          0.8326823115348816,
          0.5675455927848816,
          -0.8994140625,
          0.4943034052848816,
          -1.1201171875,
          -0.7410482168197632,
          0.9534505605697632,
          0.480224609375,
          -1.166015625,
          0.3828938901424408,
          -2.197265625,
          -0.8235677480697632,
          -0.8714193105697632,
          -1.6966146230697632,
          -1.8997396230697632,
          -1.1858724355697632,
          -1.9752604961395264,
          -0.5296224355697632,
          -0.3356119990348816,
          0.2260335385799408,
          -2.3098959922790527,
          -0.0271428432315588,
          0.0993448942899704,
          -0.0626983642578125,
          0.34375,
          -0.1900227963924408,
          0.2339681088924408,
          -0.4440104365348816,
          0.209716796875,
          0.19482421875,
          0.47998046875,
          0.3146159052848816,
          0.3494466245174408,
          -0.33203125,
          -0.7854818105697632
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "red"
         },
         "name": "Max(Incorrect) Answer Logit-Dif",
         "showlegend": false,
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41
         ],
         "xaxis": "x2",
         "y": [
          -0.5651041865348816,
          0.019247692078351974,
          -0.2075602263212204,
          -0.5091146230697632,
          -0.4292806088924408,
          -0.1999918669462204,
          -0.7516276240348816,
          -0.1795247495174408,
          -0.1014811247587204,
          0.5008138418197632,
          -0.6329752802848816,
          0.7000325918197632,
          0.2108154296875,
          -0.39208984375,
          -0.252899169921875,
          0.313232421875,
          -0.210235595703125,
          2.3782553672790527,
          0.327972412109375,
          0.1983286589384079,
          1.55859375,
          1.60546875,
          1.1686198711395264,
          0.4609375,
          0.3471272885799408,
          -0.2535807490348816,
          -0.018327077850699425,
          -0.8727213740348816,
          0.4383952021598816,
          0.2237955778837204,
          -0.1774088591337204,
          0.2433268278837204,
          -0.0413055419921875,
          0.0430806502699852,
          -0.1507568359375,
          0.0838623046875,
          0.268310546875,
          0.5843099355697632,
          0.1621907651424408,
          0.0912068709731102,
          -0.30810546875,
          -1.1028646230697632
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "hook_mlp_out Logit Differences",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "attn.hook_z Logit Differences",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "barmode": "group",
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Ablation logit differences: Corrupted setting"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "dtick": 1,
         "range": [
          1,
          42
         ],
         "tickmode": "linear",
         "title": {
          "text": "Layer"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ],
         "dtick": 1,
         "range": [
          1,
          42
         ],
         "tickmode": "linear",
         "title": {
          "text": "Layer"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Logit Difference<br>(Baseline - Ablated)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Logit Difference<br>(Baseline - Ablated)"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"8aa85ab5-cc35-46a1-a36a-96026746e35f\" class=\"plotly-graph-div\" style=\"height:800px; width:1200px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8aa85ab5-cc35-46a1-a36a-96026746e35f\")) {                    Plotly.newPlot(                        \"8aa85ab5-cc35-46a1-a36a-96026746e35f\",                        [{\"marker\":{\"color\":\"blue\"},\"name\":\"Correct Answer Logit-Dif\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41],\"y\":[0.3909098505973816,-0.3194987177848816,0.1763204038143158,0.8463541865348816,1.9016927480697632,1.5807292461395264,1.7727864980697632,1.1223958730697632,0.4496307373046875,3.7890625,-1.0960286855697632,-1.1604818105697632,-0.3006591796875,0.4226888120174408,-2.2565104961395264,-0.7977702021598816,-2.2623698711395264,-0.588623046875,-2.1165366172790527,-1.302734375,0.6897786855697632,-0.3949788510799408,-1.2916667461395264,-0.42626953125,-2.0748698711395264,-1.4036458730697632,-0.8994140625,-0.59033203125,-0.25048828125,-0.6793619990348816,-0.4850260615348816,-0.3937174677848816,-0.3411458432674408,-0.6783854365348816,-0.30712890625,-0.2246907651424408,-0.3177083432674408,1.4466146230697632,0.49072265625,-0.1345621794462204,0.1212361678481102,-2.42578125],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"red\"},\"name\":\"Max(Incorrect) Answer Logit-Dif\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41],\"y\":[-0.3805338740348816,-0.04638671875,-0.1916300505399704,-0.2562662959098816,-0.5060221552848816,-0.5107421875,-0.49072265625,-0.28143310546875,-0.19476318359375,-0.5506185293197632,0.357666015625,0.5701497793197632,0.2328592985868454,-0.16940180957317352,2.4342448711395264,0.8600260615348816,2.9166667461395264,0.6474609375,2.76171875,0.779296875,-0.3954264521598816,0.60986328125,0.37818145751953125,-0.6396484375,0.5628255605697632,-0.5665690302848816,-0.701171875,-0.0988667830824852,-0.1597493588924408,-0.2867838740348816,-0.3430989682674408,-0.1761067807674408,-0.2496744841337204,-0.294189453125,-0.4217122495174408,-0.03450775146484375,0.0131963100284338,0.546875,0.7047526240348816,-0.0281016044318676,-0.0376637801527977,-2.4622397422790527],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"blue\"},\"name\":\"Correct Answer Logit-Dif\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41],\"y\":[1.1962890625,-0.3151041865348816,0.3368327021598816,1.921875,1.4029948711395264,0.12837982177734375,2.3111979961395264,0.8326823115348816,0.5675455927848816,-0.8994140625,0.4943034052848816,-1.1201171875,-0.7410482168197632,0.9534505605697632,0.480224609375,-1.166015625,0.3828938901424408,-2.197265625,-0.8235677480697632,-0.8714193105697632,-1.6966146230697632,-1.8997396230697632,-1.1858724355697632,-1.9752604961395264,-0.5296224355697632,-0.3356119990348816,0.2260335385799408,-2.3098959922790527,-0.0271428432315588,0.0993448942899704,-0.0626983642578125,0.34375,-0.1900227963924408,0.2339681088924408,-0.4440104365348816,0.209716796875,0.19482421875,0.47998046875,0.3146159052848816,0.3494466245174408,-0.33203125,-0.7854818105697632],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"red\"},\"name\":\"Max(Incorrect) Answer Logit-Dif\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41],\"y\":[-0.5651041865348816,0.019247692078351974,-0.2075602263212204,-0.5091146230697632,-0.4292806088924408,-0.1999918669462204,-0.7516276240348816,-0.1795247495174408,-0.1014811247587204,0.5008138418197632,-0.6329752802848816,0.7000325918197632,0.2108154296875,-0.39208984375,-0.252899169921875,0.313232421875,-0.210235595703125,2.3782553672790527,0.327972412109375,0.1983286589384079,1.55859375,1.60546875,1.1686198711395264,0.4609375,0.3471272885799408,-0.2535807490348816,-0.018327077850699425,-0.8727213740348816,0.4383952021598816,0.2237955778837204,-0.1774088591337204,0.2433268278837204,-0.0413055419921875,0.0430806502699852,-0.1507568359375,0.0838623046875,0.268310546875,0.5843099355697632,0.1621907651424408,0.0912068709731102,-0.30810546875,-1.1028646230697632],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Layer\"},\"tickmode\":\"linear\",\"dtick\":1,\"range\":[1,42]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"title\":{\"text\":\"Logit Difference\\u003cbr\\u003e(Baseline - Ablated)\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Layer\"},\"tickmode\":\"linear\",\"dtick\":1,\"range\":[1,42]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375],\"title\":{\"text\":\"Logit Difference\\u003cbr\\u003e(Baseline - Ablated)\"}},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"hook_mlp_out Logit Differences\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"attn.hook_z Logit Differences\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Ablation logit differences: Corrupted setting\"},\"height\":800,\"width\":1200,\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8aa85ab5-cc35-46a1-a36a-96026746e35f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for hook_type in HOOK_TYPES:\n",
    "    for layer in range(N_LAYERS):\n",
    "        result = {\n",
    "            'layer': layer,\n",
    "            'hook_type': hook_type,\n",
    "            'logit_diffs': ablation_difs_dict[hook_type][layer].cpu().numpy(),\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "plot_logit_diffs(results, title_suffix='Corrupted setting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
